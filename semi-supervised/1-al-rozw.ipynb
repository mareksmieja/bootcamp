{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Weź 300 przykładów zbioru digits. Porównaj wynik klasyfikacji biorąc jako test ustalone 100 przykładów, a jako trening 10,20,...,100 przykładów. Uruchom logistyczną regresję i narysuj zależność accuracy od ilości danych w treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "rng = np.random.RandomState(0)\n",
    "indices = np.arange(len(digits.data))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X = digits.data[indices[:300]]\n",
    "y = digits.target[indices[:300]]\n",
    "images = digits.images[indices[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.333,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 64)\n",
      "(100, 64)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(len(set(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marek\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tab = []\n",
    "inds = range(X_train.shape[0])\n",
    "num_training = [10,20,30,40,50,60,70,80,90,100]\n",
    "random.seed(0)\n",
    "\n",
    "for k in num_training:\n",
    "    samples = random.sample(inds,k)\n",
    "    train_samples = X_train[samples, :]\n",
    "    train_labels = y_train[samples]\n",
    "#     model = LogisticRegression(C=1e5)\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(train_samples, train_labels)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tab.append(accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_training, tab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załóżmy, że możemy pozyskać 30 przykładów i możemy które przykłady chcemy poetykietować. Jak je wybrać?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=0.95,random_state=42)\n",
    "X_labeled.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Zaimplementuj active learnera z kryterium entropijnym oraz losowym. Porównaj ich działanie na postawionym powyżej problemie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator\n",
    "import copy\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "class AL(BaseEstimator):\n",
    "    def __init__(self, model, X_test, y_test, sampling_style = 'entropy', \n",
    "                 sample_num=2, upper_bound = 30, seed=42):\n",
    "        self.sample_num = sample_num\n",
    "        self.upper_bound = upper_bound\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.model.seed = seed\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.sampling_style = sampling_style\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        num = X.shape[0]    \n",
    "        X_aug = copy.deepcopy(X)\n",
    "        y_aug = copy.deepcopy(y)\n",
    "        X_pool = copy.deepcopy(X_test)\n",
    "        y_pool = copy.deepcopy(y_test)\n",
    "        while num <= self.upper_bound-X.shape[0]:\n",
    "            X_aug, y_aug, X_pool, y_pool = self.active_label(X_aug, y_aug, X_pool, y_pool)\n",
    "            num += self.sample_num\n",
    "        self.model.fit(X_aug, y_aug)\n",
    "        return self\n",
    "    \n",
    "    def active_label(self, X, y, X_pool, y_pool):\n",
    "        \n",
    "        # Train the model and creat the pseudo-labels\n",
    "        self.model.fit(X, y)\n",
    "        proba_labels = self.model.predict_proba(X_pool)\n",
    "        # Take a subset of the pool set with pseudo-labels and append in onto the training set\n",
    "        if self.sampling_style == 'entropy':\n",
    "            ind_selected = self.select_by_entropy(proba_labels)\n",
    "        else:\n",
    "            ind_selected = self.select_by_sampling(proba_labels)\n",
    "        X_aug = np.vstack((X, X_pool[ind_selected]))\n",
    "        y_aug = np.hstack((y, y_pool[ind_selected]))\n",
    "        X_pool = np.delete(X_pool, ind_selected, 0)\n",
    "        y_pool = np.delete(y_pool, ind_selected, 0)\n",
    "        \n",
    "        return X_aug, y_aug, X_pool, y_pool\n",
    "    \n",
    "    def select_by_sampling(self, proba):\n",
    "        print(\"sampling\")\n",
    "        return random.sample(range(len(proba)), self.sample_num)\n",
    "    \n",
    "      \n",
    "    def select_by_entropy(self, proba):\n",
    "        print(\"entropy\")\n",
    "        entropies = stats.distributions.entropy(proba.T)\n",
    "        inds = (np.argsort(entropies)[::-1]).tolist()\n",
    "        return inds[:self.sample_num]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Użyjmy entropijnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "entropy\n",
      "entropy\n",
      "entropy\n",
      "entropy\n",
      "entropy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AL(X_test=array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  3., ...,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  1., ..., 16.,  0.]]),\n",
       "  model=LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  sample_num=2, sampling_style='entropy', seed=42, upper_bound=30,\n",
       "  y_test=array([8, 8, ..., 1, 2]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = AL(\n",
    "    linear_model.LogisticRegression(C=1e5),\n",
    "    X_unlabeled,\n",
    "    y_unlabeled,\n",
    "    'entropy'\n",
    ")\n",
    "# Train the model and use it to predict\n",
    "model.fit(X_labeled, y_labeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ZADANIE: Użyjmy randomowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling\n",
      "sampling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AL(X_test=array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  3., ...,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  1., ..., 16.,  0.]]),\n",
       "  model=LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  sample_num=10, sampling_style='random', seed=42, upper_bound=30,\n",
       "  y_test=array([8, 8, ..., 1, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "model_random = AL(\n",
    "    linear_model.LogisticRegression(C=1e5),\n",
    "    X_unlabeled,\n",
    "    y_unlabeled,\n",
    "    'random'\n",
    ")\n",
    "# Train the model and use it to predict\n",
    "model_random.fit(X_labeled, y_labeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_random.predict(X_train)\n",
    "y_test_pred = model_random.predict(X_test)\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Weź jakiś klasyfikator nieliniowy i spradź działanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marek\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\marek\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AL(X_test=array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  3., ...,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  1., ..., 16.,  0.]]),\n",
       "  model=LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001),\n",
       "  sample_num=10, sampling_style='entropy', seed=42, upper_bound=30,\n",
       "  y_test=array([8, 8, ..., 1, 2]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "model = AL(\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    X_unlabeled,\n",
    "    y_unlabeled,\n",
    "    'entropy'\n",
    ")\n",
    "# Train the model and use it to predict\n",
    "model.fit(X_labeled, y_labeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_random.predict(X_train)\n",
    "y_test_pred = model_random.predict(X_test)\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
