{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Latent Dirichlet Allocation</h1>\n",
    "\n",
    "LSI pozwala w pewnym sensie znajdowac kluczowe tematy w tekście i dla danego dokumentu określać najbliższy mu temat. Jest to podejście geometryczne. \n",
    "\n",
    "LDA jest podejściem probabilistycznym do modelowania tematów. Jest bardziej dokładny choć wolniejszy."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bierzemy macierz częstości słów $W_i$ w dokumentach $D_i$:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Załóżmy że mamy $k$ tematów. Każdy temat jest charakteryzowany słowami (jedne słowa pojawiają się częściej inne rzadziej). \n",
    "\n",
    "<h2>Częstości</h2>\n",
    "\n",
    "Jeśli przejdziemy po dokumentach i przyporządkujemy każde słowo do określonego tematu, to powstaną 2 macierze\n",
    "\n",
    "Dokument-temat\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Temat-słowo\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Mając powyższe macierze możemy policzyć prawdopodobieństwa:\n",
    "\n",
    "-$p_1$ - przynależności dokumentu do tematu\n",
    "\n",
    "-$p_2$ - przynależności słowa do tematu\n",
    "\n",
    "LDA dąży do jak najlepszego przyporządkowania słów poszczególnych dokumentów do tematów (maksymalizowana jest funkcja wiarygodności).\n",
    "\n",
    "\n",
    "<h2>Generatywność</h2>\n",
    "\n",
    "Mając prawdopodobieństwa $p_1$, $p_2$ możemy wygeneraować dokument:\n",
    "\n",
    "-wybieramy (losujemy) prawdopodobieństwo przynależności dokumentu do tematu (z $p_1$) - dokuemnt zawsze należy do wielu tematów\n",
    "\n",
    "-generujemy słowa w dokumencie - najpierw losujemy do jakiego tematu należy słowo, a potem generujemy słowo z tego tematu $(z $p_2$)\n",
    "\n",
    "<h2> Przykład</h2>\n",
    "\n",
    "Let’s make an example. According to the above process, when generating some particular document D, you might\n",
    "\n",
    "Pick 5 to be the number of words in D.\n",
    "Decide that D will be 1/2 about food and 1/2 about cute animals.\n",
    "Pick the first word to come from the food topic, which then gives you the word “broccoli”.\n",
    "Pick the second word to come from the cute animals topic, which gives you “panda”.\n",
    "Pick the third word to come from the cute animals topic, giving you “adorable”.\n",
    "Pick the fourth word to come from the food topic, giving you “cherries”.\n",
    "Pick the fifth word to come from the food topic, giving you “eating”.\n",
    "So the document generated under the LDA model will be “broccoli panda adorable cherries eating” (note that LDA is a bag-of-words model).\n",
    "\n",
    "<h2>Uczenie</h2>\n",
    "\n",
    "1. Idziemy przez wszystkie słowa i wszystkie dokumentu i losowo przyporządkowujemy je do tematów.\n",
    "2. Iteracyjnie idzemy: bierzemy dokuemnt $d$  i słowo $w$ i przyporządkowujemy je do najlepiej pasującego tematu - maksymalizującego $P(d|t)P(t|w)$\n",
    "3. Po przejsciu przez wszystkie dokumenty aktualizujemy macierze i wracamy do punktu 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierzemy korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary.load('tmp/deerwester.dict')\n",
    "corpus = corpora.MmCorpus('tmp/deerwester.mm') # comes from the first tutorial, \"From strings to vectors\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budujemy model LDA i transformujemy dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.13602643), (1, 0.86397356)]\n",
      "[(0, 0.40377942), (1, 0.59622055)]\n",
      "[(0, 0.14303932), (1, 0.85696065)]\n",
      "[(0, 0.11303401), (1, 0.88696593)]\n",
      "[(0, 0.83884501), (1, 0.16115502)]\n",
      "[(0, 0.70216995), (1, 0.29783002)]\n",
      "[(0, 0.80885631), (1, 0.19114368)]\n",
      "[(0, 0.86016876), (1, 0.13983129)]\n",
      "[(0, 0.8522082), (1, 0.14779183)]\n"
     ]
    }
   ],
   "source": [
    "model = models.LdaModel(corpus, id2word=dictionary, num_topics=2)\n",
    "corpus_lda = model[corpus] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
    "for d in corpus_lda:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla każdego dokumentu dostajemy prawdopodobieństwo przynależności dokumentu do danego tematu.\n",
    "\n",
    "Możemy też zobaczyć z czego składają się tematy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.140*\"graph\" + 0.125*\"trees\" + 0.115*\"user\" + 0.109*\"minors\" + 0.094*\"response\" + 0.084*\"time\" + 0.078*\"survey\" + 0.072*\"system\" + 0.060*\"eps\" + 0.049*\"interface\"'),\n",
       " (1,\n",
       "  '0.171*\"system\" + 0.113*\"human\" + 0.104*\"computer\" + 0.097*\"interface\" + 0.086*\"eps\" + 0.080*\"user\" + 0.070*\"trees\" + 0.068*\"survey\" + 0.063*\"time\" + 0.056*\"graph\"')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Chcemy postortowac słowa każdego tematu i wybrać 5 najważniejszych - co można powiedzieć o tematach?\n",
    "\n",
    "Proszę zobaczyć na funkcje typu get_topics(), get_term_topics(...): https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph\n",
      "trees\n",
      "user\n",
      "minors\n",
      "response\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "topics = np.argsort(model.get_topics()[0,:])[::-1] #::-1 sortowanie w odwrotnej kolejności\n",
    "for x in topics[:5]:\n",
    "    print(dictionary[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę posortować zdania najbardziej pasujące do danego tematu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 1.0), (10, 1.0), (11, 1.0)]\n",
      "[(9, 1.0), (10, 1.0)]\n",
      "[(0, 1.0), (1, 1.0), (2, 1.0)]\n",
      "[(9, 1.0)]\n",
      "[(3, 1.0), (6, 1.0), (7, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# for d in corpus_lda:\n",
    "#     print(d)\n",
    "    \n",
    "# for d in corpus_lda:\n",
    "#     print(d[0])\n",
    "\n",
    "#print(corpus_lda[0][0])\n",
    "\n",
    "numpy_corpus = gensim.matutils.corpus2dense(corpus_lda, num_terms=2)\n",
    "docs = np.argsort(numpy_corpus[0,:])[::-1]\n",
    "for x in docs[:5]:\n",
    "    print(corpus[x])\n",
    "    \n",
    "#trzeba by wypisać raczej zdania niż ich reprezentacje bag-of-words, ale tu nie mam dostepu do tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Sprawdzić do jakiego tematu pasuje nowy dokument i jakie są mu najbliższe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "doc = \"Human computer interaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.45015991), (1, 0.54984009)]\n"
     ]
    }
   ],
   "source": [
    "doc_rep = dictionary.doc2bow(doc.split(' '))\n",
    "\n",
    "doc_assignments = model[doc_rep]\n",
    "print(doc_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz trzebaby przygotować similarity query jak w LSI i zobaczyć wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W sklearn też jest LDA. Proszę spróbować samodzielnie użyć go i porównać wyniki z gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wizualizacja modeli</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do wizualizacji użyjemy biblioteki pyLDAvis. instalujemy pyLDAvis: https://github.com/bmabey/pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el112432335492277365958423595\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el112432335492277365958423595_data = {\"mdsDat\": {\"Freq\": [56.70882343205248, 43.291176567947524], \"cluster\": [1, 1], \"topics\": [1, 2], \"x\": [0.024349946528673172, -0.024349946528673172], \"y\": [0.0, 0.0]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.7990486333861, 2.960099746042843, 1.4230408230375255, 1.2412851597332897, 1.2350622813582985, 1.2296134184340097, 1.2288514108215485, 1.5113495286863823, 0.9896618283589176, 1.2924373253506238, 0.8818316247475675, 0.6532771885687121, 1.3570388108220566, 1.8007807189279212, 1.473508245841565, 1.0889240870091121, 1.2990249362383255, 0.8982786483678584, 0.8976713069368258, 0.8933284368765437, 0.8883685909839667, 0.7435004487134506, 0.7702123874405387, 0.4438044381761935], \"Term\": [\"trees\", \"interface\", \"system\", \"survey\", \"graph\", \"minors\", \"user\", \"computer\", \"time\", \"response\", \"human\", \"eps\", \"survey\", \"system\", \"eps\", \"human\", \"response\", \"time\", \"computer\", \"user\", \"minors\", \"graph\", \"trees\", \"interface\", \"interface\", \"trees\", \"graph\", \"minors\", \"user\", \"computer\", \"time\", \"response\", \"human\", \"eps\", \"system\", \"survey\"], \"Total\": [2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.2428530715622936, 3.7303121334833818, 2.166541271750976, 2.1296537507172566, 2.1283907182348423, 2.127284725370836, 2.127130059189407, 2.810374464924708, 2.0785859153680297, 2.765945571192189, 2.6826123436754887, 2.0103159993907687, 2.0103159993907687, 2.6826123436754887, 2.765945571192189, 2.0785859153680297, 2.810374464924708, 2.127130059189407, 2.127284725370836, 2.1283907182348423, 2.1296537507172566, 2.166541271750976, 3.7303121334833818, 2.2428530715622936], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3467, 0.336, 0.1469, 0.0274, 0.023, 0.0191, 0.0185, -0.0531, -0.1748, -0.1936, -0.5453, -0.5568, 0.4442, 0.4387, 0.2075, 0.1907, 0.0655, -0.0248, -0.0256, -0.0309, -0.0371, -0.2323, -0.7404, -0.7829], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.2128000259399414, -1.7148000001907349, -2.4472999572753906, -2.583899974822998, -2.588900089263916, -2.593400001525879, -2.5940001010894775, -2.3870999813079834, -2.8104000091552734, -2.5434999465942383, -2.925800085067749, -3.225800037384033, -2.2248001098632812, -1.9419000148773193, -2.142400026321411, -2.4449000358581543, -2.2685000896453857, -2.6373000144958496, -2.638000011444092, -2.642899990081787, -2.648400068283081, -2.8264999389648438, -2.7911999225616455, -3.342400074005127]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.47011699904286697, 0.47011699904286697, 0.46156517442744605, 0.46156517442744605, 0.3615400138076383, 0.3615400138076383, 0.4695598989569103, 0.4695598989569103, 0.4974342343706425, 0.4974342343706425, 0.48109630331202463, 0.48109630331202463, 0.4698385458236442, 0.4698385458236442, 0.8917213638996287, 0.8042222453911885, 0.2680740817970628, 0.47008281875651436, 0.47008281875651436, 0.37277096795502124, 0.7455419359100425, 0.7116489368094161, 0.35582446840470805], \"Term\": [\"computer\", \"computer\", \"eps\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"]}, \"R\": 12, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el112432335492277365958423595\", ldavis_el112432335492277365958423595_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el112432335492277365958423595\", ldavis_el112432335492277365958423595_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el112432335492277365958423595\", ldavis_el112432335492277365958423595_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pytania które warto zadać: \n",
    "\n",
    "-jaki model jest dobry? powinny być interpretowalne, separowalne\n",
    "\n",
    "-co znaczą te miary w ldavis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosowania: querowanie, rekomendacja, reprezentacja do klasyfiakcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początek niech wezmą tutorial gensim, pobiorą dokument i stworzą reprezentację. Potem będziemy opowiadać o LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIA:\n",
    "\n",
    "1. Mamy posty (tweety) użytkowników. Bierzemy jakiegoś użytkownika (zakładamy, że znamy dobrze jego zachowanie) i pytamy się, którzy użytkownicy są do niego podobni. Jeśli ich znajdziemy będziemy mogli im dedykować analogiczne reklamy i treści.\n",
    "\n",
    "Rozw: można potraktować posty tego użytkownika jak query i wyszukać najbardziej podobne dokumenty innych użytkowników. Jeśli uzytkownicy mają dużo postów to trzeba jakąś miarę na zbiorach postów - dla prostoty porównujemy średnie, ale można też jakieś linkage functions z hierarchicznego wziąć.\n",
    "\n",
    "\n",
    "2. Pytamy się o czym jest dany tekst. \n",
    "\n",
    "Rozw: Najprostsze rozwiązanie to znalezienie najczęstszych słów. Bardzej zaawansowane polega na wyszukaniu topiców (LSA albo LDA) - wtedy mamy niezależne topici.\n",
    "\n",
    "3. Mamy podział na topici. Bierzemy użytkownika. Pytamy się którzy użytkownicy są do niego podobni biorąc pod uwagę tylko określony topic (na przykład pytamy sie którzy są podobni w kategorii sport. Zadanie możemy rozszerzyć na pytanie, którzy uyżytkownicy są do niego podobni biorąc pod uwagę kilka topiców na raz.\n",
    "\n",
    "Rozw: Jeśli mamy topic albo topici to wystarczy zrzutować naszego użytkownika na tą podprzestrzeń. Tak samo robimy z innymi użytkownikami i szukamy najbliższych w tej podprzestrzeni.\n",
    "\n",
    "4. Mamy podział na topici - które słowa charakteryzują najbardzie dany topic\n",
    "\n",
    "Bierzemy te współrzędne (słowa) z największą normą z kolejnych wektorów własnych.\n",
    "\n",
    "5. Jakie zdania najbardziej charakteryzują topic?\n",
    "\n",
    "Jest to chyba opisane w https://towardsdatascience.com/nlp-for-topic-modeling-summarization-of-legal-documents-8c89393b1534 ale nie dokonca rozumiem. Jest tez notebook: https://github.com/chibueze07/Machine-Learning-In-Law/tree/master\n",
    "\n",
    "6. Jakich osób (podmiotów) dotyczą topici. Trzeba zrobic POS i dla każdego podmiotu wyszukać podobieństwo do danego topicu. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
