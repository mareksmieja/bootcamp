{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Wyszukiwanie w tekstach</h1>\n",
    "\n",
    "Kluczowym problemem nlp jest wyszukiwanie podobnych dokumentów.\n",
    "\n",
    "ZADANIE: Prosze wczytać słownik i korpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "dictionary = corpora.Dictionary.load('tmp/deerwester.dict')\n",
    "corpus = corpora.MmCorpus('tmp/deerwester.mm') # comes from the first tutorial, \"From strings to vectors\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierzemy nowy dokument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W gensim najpierw inicjalizujemy query (tworzymy macierz podobieństw) a potem możemy querować podobne dokuenty. Do querowania używane jest podobieństwo cosinusowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.99999994,  0.23570226,  0.28867513,  0.23570226,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), array([ 0.23570226,  1.        ,  0.40824831,  0.33333334,  0.70710677,\n",
      "        0.        ,  0.        ,  0.        ,  0.23570226], dtype=float32), array([ 0.28867513,  0.40824831,  1.        ,  0.61237246,  0.28867513,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), array([ 0.23570226,  0.33333334,  0.61237246,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), array([ 0.        ,  0.70710677,  0.28867513,  0.        ,  0.99999994,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.70710677,  0.57735026,  0.        ], dtype=float32), array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.70710677,  0.99999994,  0.81649655,  0.40824828], dtype=float32), array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.57735026,  0.81649655,  0.99999994,  0.66666663], dtype=float32), array([ 0.        ,  0.23570226,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.40824828,  0.66666663,  0.99999994], dtype=float32)]\n",
      "[(0, 0.81649655), (1, 0.28867513), (2, 0.0), (3, 0.28867513), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(corpus)\n",
    "\n",
    "print(list(index))\n",
    "\n",
    "\n",
    "\n",
    "sims = index[vec_bow] # perform a similarity query against the corpus\n",
    "\n",
    "print(list(enumerate(sims))) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę posortować korpus od najbardziej pasujących."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.81649655), (1, 0.28867513), (3, 0.28867513), (2, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims) # print sorted (document number, similarity score) 2-tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę zaanalizować wynik. Jakie dokumenty okazały się najbardziej podobne.\n",
    "\n",
    "ZADANIE: Proszę użyć tfidf do analogicznego zadania. Należy stworzyć odpowiednie funkcje które pozwolą nam yżywać róóżnych transformacji do querowania.\n",
    "\n",
    "Czy wynik się różni? Co się zmieniło?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.81649655), (1, 0.31412902), (2, 0.0), (3, 0.34777319), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n",
      "[(0, 0.81649655), (3, 0.34777319), (1, 0.31412902), (2, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus, id2word=dictionary)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "vec_tfidf = tfidf[vec_bow]\n",
    "\n",
    "index = similarities.MatrixSimilarity(corpus_tfidf)\n",
    "\n",
    "sims = index[vec_tfidf]\n",
    "\n",
    "print(list(enumerate(sims)))\n",
    "\n",
    "#sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Teraz proszę zrobić to samo z LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.99809301), (1, 0.93748635), (2, 0.99844527), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.098794639), (8, 0.050041765)]\n",
      "[(2, 0.99844527), (0, 0.99809301), (3, 0.9865886), (1, 0.93748635), (4, 0.90755945), (8, 0.050041765), (7, -0.098794639), (6, -0.10639259), (5, -0.12416792)]\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    "\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "\n",
    "sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims)))\n",
    "\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę zauważyć że w LSI pasujące dokumenty nie muszą zawierać słów które występuja w query. Dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początek niech wezmą tutorial gensim, pobiorą dokument i stworzą reprezentację. Potem będziemy opowiadać o LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIA:\n",
    "\n",
    "1. Mamy posty (tweety) użytkowników. Bierzemy jakiegoś użytkownika (zakładamy, że znamy dobrze jego zachowanie) i pytamy się, którzy użytkownicy są do niego podobni. Jeśli ich znajdziemy będziemy mogli im dedykować analogiczne reklamy i treści.\n",
    "\n",
    "Rozw: można potraktować posty tego użytkownika jak query i wyszukać najbardziej podobne dokumenty innych użytkowników. Jeśli uzytkownicy mają dużo postów to trzeba jakąś miarę na zbiorach postów - dla prostoty porównujemy średnie, ale można też jakieś linkage functions z hierarchicznego wziąć.\n",
    "\n",
    "\n",
    "2. Pytamy się o czym jest dany tekst. \n",
    "\n",
    "Rozw: Najprostsze rozwiązanie to znalezienie najczęstszych słów. Bardzej zaawansowane polega na wyszukaniu topiców (LSA albo LDA) - wtedy mamy niezależne topici.\n",
    "\n",
    "3. Mamy podział na topici. Bierzemy użytkownika. Pytamy się którzy użytkownicy są do niego podobni biorąc pod uwagę tylko określony topic (na przykład pytamy sie którzy są podobni w kategorii sport. Zadanie możemy rozszerzyć na pytanie, którzy uyżytkownicy są do niego podobni biorąc pod uwagę kilka topiców na raz.\n",
    "\n",
    "Rozw: Jeśli mamy topic albo topici to wystarczy zrzutować naszego użytkownika na tą podprzestrzeń. Tak samo robimy z innymi użytkownikami i szukamy najbliższych w tej podprzestrzeni.\n",
    "\n",
    "4. Mamy podział na topici - które słowa charakteryzują najbardzie dany topic\n",
    "\n",
    "Bierzemy te współrzędne (słowa) z największą normą z kolejnych wektorów własnych.\n",
    "\n",
    "5. Jakie zdania najbardziej charakteryzują topic?\n",
    "\n",
    "Jest to chyba opisane w https://towardsdatascience.com/nlp-for-topic-modeling-summarization-of-legal-documents-8c89393b1534 ale nie dokonca rozumiem. Jest tez notebook: https://github.com/chibueze07/Machine-Learning-In-Law/tree/master\n",
    "\n",
    "6. Jakich osób (podmiotów) dotyczą topici. Trzeba zrobic POS i dla każdego podmiotu wyszukać podobieństwo do danego topicu. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
