{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> Uczenie z danych tekstowych</h1>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie tekstów to obecnie jedno z kluczowych zagadnień analizy danych. \n",
    "\n",
    "Podstawowe zadania poruszone dziś:\n",
    "<ul>\n",
    "    <li>wyszukiwanie/rekomendacja dokumentów dla danego zapytania</li> \n",
    "    <li>klasyfiakcja na danych tekstowych</li>\n",
    "    <li>wydobywanie informacji z tekstu</li>\n",
    "</ul>\n",
    "Problematyka jest o wiele szersza (tłumaczenie maszynowe, analiza składniowa, generowanie tekstu, itp.), być może wrócimy do tego tematu na ostatnich zajęciach.\n",
    "\n",
    "Aby móc radzić sobie z powyższymi zadnaiami konieczne jest zdefiniowanie miary podobieństwa na dancyh tekstowych (co to znaczy że tekty są podobne). Propozycje?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teksty nie są podane w formie wektorowej - są to ciągi znaków. Pierwszym zadniem na dziś będzie budowa wektorowej reprezentacji tekstów (dokumentów). \n",
    "\n",
    "Najprostsza reprezentacja: każde słowo reprezentuje atrybut - jeśli dokument posiada słowo to wartość atrybutu jest 1, a jeśli nie to 0.\n",
    "\n",
    "\n",
    "Na tą fazę składa się:\n",
    "<ul>\n",
    "    <li>tokenizacja</li> \n",
    "    <li>czyszczenie tekstu: usuwanie stop words / stemowanie / lematyzacja</li>\n",
    "    <li>zliczanie częstości</li>\n",
    "    <li>opcjonalnie: normalizacja</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Będziemy używać nltk. Jeśli ktoś nie ma to instalujemy.\n",
    "\n",
    "Piszemy: \"conda install nltk\" bądż \"pip install nltk\" w konsoli.\n",
    "\n",
    "Następnie \"nltk.download()\" w interpreterze i powinno działać."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tokenizacja i czyszczenie tekstu</h2>\n",
    "\n",
    "Jest to podział dokumentu na atomowe częsci np. słowa. Istnieją różne tokenizatory które są dedykowane do okreslonych danych np. tekst w książce jest inny od tekstu w tweetach (inne są tam interesujące ciągi znaków)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Bierzemy tekst (dokument). Proszę podzielić ten dokument na zdania - każde zdanie będzię dla nas jednym przykładem uczącym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard. I'm 20 years old.\"\n",
    "\n",
    "#TODO\n",
    "#sentences = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czy są jakieś artefakty? \n",
    "\n",
    "Do lepszej tokenizacji będziemy używać nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dostaliśmy zbiór zdań, który będzie naszym korpusem (zbiorem danych tekstowych). Teraz chcemy zamienić każde zdanie na wektor -- atrybuty będą identyfikowane przez tokeny (np. słowa), a wartość na danym atrybucie to ilość danego tokenu w zdaniu. Wpierw musimy wydzielić tokeny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę wziąć pierwsze zdanie i podzielić je na słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy użyć nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znak zapytania został potraktowany jako osobny token.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Istnieją inne tokenizatory, które bardziej nadają się do tekstów potocznych np. tweetów. Proszę poeksperymentować z TweetTokenizer z nltk: https://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę podzielić wszystkie zdania na tokeny i zrobić listę list jako wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musimy podjąć decyzję czy takie tokeny nam odpowiadają. Możemy usunąć punktory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę przefiltrować stokenizowane zdanie tak aby usunąć tokeny będące punktorami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę w ten sposób przefiltrować cały dokument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Czy liczby są dla nas interesujące? Proszę usunąć tokenty będące liczbami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Czasem wiedza że w tekście są liczby jest ważna - proszę zastąpić liczby ustalonym tokenem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Warto czasem nierozróżniać dużych i małych liter. Inaczej słowo pisane z dużej i małej litery będzie znaczyło co innego. Proszę zamienić wszystkie tokeny na pisane małymi literami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Zbierzmy to czego się nauczyliśmy. Proszę napisać zestaw funkcji:\n",
    "<ul>\n",
    "<li>doc2sen - bierze dokument i dzili go na zdania</li>\n",
    "<li>sen2token - bierze zdanie i dzieli go na tokeny</li>\n",
    "<li>remove_punctuation - bierze listę tokenów i usuwa punktory</li>\n",
    "<li>remove_numbers - bierze listę tokenów i usuwa liczby</li>\n",
    "<li>to_lower - bierze listę tokenów i zamienia na małe litery</li>\n",
    "<li>preprocessText - bierze listę dokumentów i wykonuje wszystki funkcje poza pierwszą</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Teksty ze stron internetowych</h1>\n",
    "\n",
    "W praktyce mamy głównie do czynienia z tekstami ze stron internetowych. W takim przypadku musimy pobrać tekst strony i dodatowo oczyścić z kodu html. Pokażemy jak to zrobić na uproszczonym przykładzi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierzemy tekst zawierający html. Pierwszym krokiem jest usunięcie znaczników html. Użyjemy do tego BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n<i>Italicized Text</i>\\n<img src=\"this should all be gone\"/>\\n<a href=\"this will be gone, too\">But this will still be here!</a>\\nI run. He ran. She is running. Will they stop running?\\nI talked. She was talking. They talked to them about running. Who ran to the talking runner?\\n\\n¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!\\nsomething... is! wrong() with.,; this :: sentence.\\nI can\\'t do this anymore. I didn\\'t know them. Why couldn\\'t you have dinner at the restaurant?\\nMy favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\\nDon\\'t do it.... Just don\\'t. Billy! I know what you\\'re doing. This is a great little house you\\'ve got here.\\n\\nJohn: \"Well, well, well.\"\\nJames: \"There, there. There, there.\"\\n&nbsp;&nbsp;\\nThere are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\\nI have to go get 2 tutus from 2 different stores, too.\\n22    45   1067   445\\n{{Here is some stuff inside of double curly braces.}}\\n{Here is more stuff in single curly braces.}\\n\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_html = \"\"\"<h1>Title Goes Here</h1>\n",
    "<b>Bolded Text</b>\n",
    "<i>Italicized Text</i>\n",
    "<img src=\"this should all be gone\"/>\n",
    "<a href=\"this will be gone, too\">But this will still be here!</a>\n",
    "I run. He ran. She is running. Will they stop running?\n",
    "I talked. She was talking. They talked to them about running. Who ran to the talking runner?\n",
    "\n",
    "¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!\n",
    "something... is! wrong() with.,; this :: sentence.\n",
    "I can't do this anymore. I didn't know them. Why couldn't you have dinner at the restaurant?\n",
    "My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\n",
    "Don't do it.... Just don't. Billy! I know what you're doing. This is a great little house you've got here.\n",
    "\n",
    "John: \"Well, well, well.\"\n",
    "James: \"There, there. There, there.\"\n",
    "&nbsp;&nbsp;\n",
    "There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\n",
    "I have to go get 2 tutus from 2 different stores, too.\n",
    "22    45   1067   445\n",
    "{{Here is some stuff inside of double curly braces.}}\n",
    "{Here is more stuff in single curly braces.}\n",
    "\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "sample_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Prosze uruchomić odpowiednie z naszych funkcji aby oczyścić resztę tekstu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobierzemy teraz tekst prosto ze strony http://news.bbc.co.uk/2/hi/health/2284783.stm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesujący jest fragment w div z klasą body_text - pobierzmy go i podzielmy na tokeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz trzeba by go porządnie oczyścić - zadanie domowe dla chętnych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę podstronę serwisu onet i wydobyć z niego tekst.\n",
    "\n",
    "Dla chętnych - proszę z głównej strony wziąć listę podstron i z każdej wydobyć tekst (web crawling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analiza częstości słów</h1>\n",
    "\n",
    "Wiemy już jak przetwarzaćtekst. Okazuje sięże potrzeba nam jeszcze kilku praktycznych spostrzeżeń dotyczących częstości słów w tekście.\n",
    "\n",
    "Pobierzemy sobie rzeczywisty tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobierzemy teraz kilka książek z nltk i sprawdzimy jaka jest różnorodność słów i jakie słowa dominują"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Ile różnych słów zawiera piersza książka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: O czym jest pierwsza książka. Zobaczmy jakie są njczęstsze słowa w tym tekście i ile razy występują.\n",
    "\n",
    "proszę użyć funkcji FreqDist na tekście (http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist). Ta funkcja stworzy nam słownik: słowo - ilość na tekście.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Czy te słowa sąinformatywne? Ile razy wstępuje słowo 'whale' (o nim chyba jest książka)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Narysujmy wykres częstości. Proszę narysować ilości słów poczynając od najczęstszych. Proszę zobaczyć: https://martinapugliese.github.io/plotting-the-actual-frequencies-in-a-FreqDist-in-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile razy średnio powtarza się jedno słowo w tekście"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać że wiele nieinformatywnych słów występuje stanowczo za często.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najczęściej występują stopwordsy, które raczej chcemy wykluczyć, bo zaburzają informacje w tekście - można je po prostu usunąć. Można uzyskać listę stopwords z nltk.corpus.stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę usunąć stopwordy i punktory. Jak teraz wyglądają najczęstsze słowa - proszę wypisać i narysować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać jeszcze jest trochę 'śmieci' w tekście"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Odmiana słów</h1>\n",
    "\n",
    "Czy odmiana słowa wpływa na znaczenie tekstu? \n",
    "\n",
    "Stemowanie - ucinanie (zmiana) końcówek słów tak aby podobne były nierozróżnialne. Stemowanie jest szybkie ale nie zawsze działa jak oczekujemy\n",
    "\n",
    "Lematyzacja - analiza słowa i doprowadzanie go do postacie podstawowej. Jest czasochłonne ale zwykle dokładniejsze niż stemowanie. Zobaczy na przykłady."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemowanie tworzy 'dziwne' słowa, lematyzacja rozsądne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Proszę wziąć jedno słowo w różnych jego odmianach i zobaczyć różnice pomiędzy stemowaniem i lematyzacją"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Weźmy nasz przykład z listą dokumentów - proszę napisać funkcję która będzie stemować tokeny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
