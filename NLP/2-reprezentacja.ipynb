{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Wektorowa reprezentacja tekstu</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W najprostszym przypadku budowanie reprezentacji wektorowej polega na zliczaniu ilości słów (ciągów). Każde słowo to atrybut a wartość w danym atrybucie to ilość wystąpniń tego słowa. \n",
    "\n",
    "\n",
    "Najprostsza reprezentacja to reprezentacja bag-of-words: https://en.wikipedia.org/wiki/Bag-of-words_model. Kazdy wektor zapisany jest w rzadkiej reprezentacji jako że słownik może być duży a dokument mały."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Weźmy tekst i podzielmy na tokeny. Proszę stworzyć słownik słów oraz policzyć częstości każdego słowa. Można użyć Counter - daje nam słownik: https://docs.python.org/2/library/collections.html#collections.Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"I need to write a program in NLTK that breaks a corpus (a large collection of txt files) into unigrams, bigrams, trigrams, fourgrams and fivegrams. I need to write a program in NLTK that breaks a corpus\"\n",
    "\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Zostańmy przy unigramach. Proszę napisać reprezentację bag-of-words. W tym celu:\n",
    "\n",
    "-tworzymy słownik słów na podstawie zdanego tekstu (metoda fit)\n",
    "\n",
    "-dla stokenizowanego dokumentu, tworzymy macierz częstości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teksto można reprezentaować też jako ciągi - co daje reprezentacja tekstu przez dłuższe ciągi? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do budowy reprezentacji używamy sklearn do tej samej czynności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE: Możemy tutaj użyć preprocessing i tokenizacje domyślną, ale można też zdefiniować własną. Proszę użyć wcześniej zdefiniowane dunkcje do przetwarzania tekstu w naszym transfromerze - zobacz: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer buduje nam słownik, czyli definiuje poszczególne wymiary. Mając taki słownik możemy transfromować nowe zdania.\n",
    "\n",
    "ZADANIE: stworzyć słownik w oparciu o zadany tekstu. Następnie wziąć dokument który zawiera słowa niebędące w słowniku - jak wygląda jego reprezentacja?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE (dla chętnych): Jeśli będzie czas to można zobaczyć na inne vektoryzery: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html. Można też spróbować wykorzystać POS do tworzenia reprezentacji: https://stackoverflow.com/questions/24002485/python-how-to-use-pos-part-of-speech-features-in-scikit-learn-classfiers-svm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
